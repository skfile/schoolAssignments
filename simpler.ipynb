{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad9502f",
   "metadata": {},
   "source": [
    "# Optimizing School District Assignments for Fairness, Efficiency, and Compactness\n",
    "\n",
    "This notebook performs experiments using the Envy-Free and MILP optimization algorithms over multiple districts with varying parameters. We analyze performance metrics such as family cost, racial imbalance, compactness, entropy, and envy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310cee0",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Imports and Setup](#1)\n",
    "2. [Load and Prepare Data](#2)\n",
    "3. [Run Optimizations](#3)\n",
    "4. [Grid Search over Lambda Values](#4)\n",
    "5. [Visualizations and Analysis](#5)\n",
    "6. [Conclusion](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0a7b8",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac31c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Import custom modules\n",
    "from envy_free import eefx_allocation_composite, compute_metrics\n",
    "from MILP_optimizer import solve_optimization\n",
    "from preprocess_data import haversine_distance  # For recomputing missing distances\n",
    "\n",
    "# Ensure plots are displayed in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Set Seaborn style for better aesthetics\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620566f",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80960376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the preprocessed data files\n",
    "blocks_file = 'gdf_blocks.pkl'\n",
    "schools_file = 'gdf_schools.pkl'\n",
    "dist_file = 'dist.pkl'\n",
    "\n",
    "# Load the blocks DataFrame\n",
    "gdf_blocks = pd.read_pickle(blocks_file)\n",
    "\n",
    "# Load the schools DataFrame\n",
    "gdf_schools = pd.read_pickle(schools_file)\n",
    "\n",
    "# Load the distance dictionary\n",
    "with open(dist_file, 'rb') as f:\n",
    "    dist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0168ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'UniqueTract' and 'UniqueSchoolID' exist and are strings\n",
    "if 'UniqueTract' not in gdf_blocks.columns:\n",
    "    gdf_blocks['UniqueTract'] = gdf_blocks['district_code'].astype(str) + '_' + gdf_blocks['Tract'].astype(str)\n",
    "if 'UniqueSchoolID' not in gdf_schools.columns:\n",
    "    gdf_schools['UniqueSchoolID'] = gdf_schools['district_code'].astype(str) + '_' + gdf_schools['SchoolID'].astype(str)\n",
    "\n",
    "gdf_blocks['UniqueTract'] = gdf_blocks['UniqueTract'].astype(str)\n",
    "gdf_schools['UniqueSchoolID'] = gdf_schools['UniqueSchoolID'].astype(str)\n",
    "\n",
    "# Update block_names and school_names\n",
    "block_names = gdf_blocks['UniqueTract'].unique().tolist()\n",
    "school_names = gdf_schools['UniqueSchoolID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3580e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all blocks in gdf_blocks are present in dist\n",
    "blocks_in_dist = set(dist.keys())\n",
    "blocks_in_gdf = set(block_names)\n",
    "missing_blocks = blocks_in_gdf - blocks_in_dist\n",
    "\n",
    "if missing_blocks:\n",
    "    print(f\"Blocks missing in dist: {len(missing_blocks)}\")\n",
    "    print(\"Recomputing distances for missing blocks...\")\n",
    "\n",
    "    # Recompute distances for missing blocks\n",
    "    for block_id in tqdm(missing_blocks, desc='Recomputing Distances'):\n",
    "        block = gdf_blocks[gdf_blocks['UniqueTract'] == block_id].iloc[0]\n",
    "        lat1, lon1 = block['Latitude'], block['Longitude']\n",
    "        dist[block_id] = {}\n",
    "        for _, school in gdf_schools.iterrows():\n",
    "            school_id = school['UniqueSchoolID']\n",
    "            lat2, lon2 = school['Latitude'], school['Longitude']\n",
    "            distance = haversine_distance(lat1, lon1, lat2, lon2)\n",
    "            dist[block_id][school_id] = distance\n",
    "\n",
    "    # Verify all blocks are now present\n",
    "    blocks_in_dist = set(dist.keys())\n",
    "    missing_blocks = blocks_in_gdf - blocks_in_dist\n",
    "    if missing_blocks:\n",
    "        print(f\"Still missing blocks in dist after recomputing: {len(missing_blocks)}\")\n",
    "    else:\n",
    "        print(\"All blocks are now present in dist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc1f20ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Racial Proportions (P_k):\n",
      "White: 0.9531\n",
      "Black: 0.0376\n",
      "Asian: 0.0093\n"
     ]
    }
   ],
   "source": [
    "# Compute overall racial proportions (P_k)\n",
    "total_race_population = gdf_blocks[['White', 'Black', 'Asian']].sum().sum()\n",
    "if total_race_population == 0:\n",
    "    total_race_population = 1e-6  # Avoid division by zero\n",
    "\n",
    "P_k = {\n",
    "    'White': gdf_blocks['White'].sum() / total_race_population,\n",
    "    'Black': gdf_blocks['Black'].sum() / total_race_population,\n",
    "    'Asian': gdf_blocks['Asian'].sum() / total_race_population\n",
    "}\n",
    "\n",
    "print(\"Overall Racial Proportions (P_k):\")\n",
    "for race, proportion in P_k.items():\n",
    "    print(f\"{race}: {proportion:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d182a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate maximum possible racial imbalance\n",
    "max_possible_imbalance = sum([abs(1 - P_k[race]) for race in P_k])\n",
    "\n",
    "# Compute maximum distance for scaling\n",
    "max_distance = max([max(dist_row.values()) for dist_row in dist.values() if dist_row])\n",
    "BigM = max_distance + 1  # For compactness constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03b65b",
   "metadata": {},
   "source": [
    "## 3. Run Optimizations <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ffd7eb8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Parameters for the algorithms\n",
    "lambda_distance = 1\n",
    "lambda_racial = 1\n",
    "lambda_capacity = 1\n",
    "capacity_slack = 1.05  # Allow schools to exceed capacity by 5%\n",
    "\n",
    "lambda_cost = 1\n",
    "lambda_imbalance = 1\n",
    "lambda_compactness = 1\n",
    "solver_time_limit = 60000  # 60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2cd4ee6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Run Envy-Free Algorithm with Composite Valuations\n",
    "def run_envy_free():\n",
    "    print(\"\\nRunning Envy-Free Algorithm with Composite Valuations...\")\n",
    "    total_population = gdf_blocks['Population'].sum()\n",
    "    num_schools = len(school_names)\n",
    "    capacity_per_school = capacity_slack * (total_population / num_schools)\n",
    "\n",
    "    allocation = eefx_allocation_composite(\n",
    "        df_blocks=gdf_blocks,\n",
    "        block_names=block_names,\n",
    "        school_names=school_names,\n",
    "        dist=dist,\n",
    "        P_k=P_k,\n",
    "        max_distance=max_distance,\n",
    "        max_possible_imbalance=max_possible_imbalance,\n",
    "        lambda_distance=lambda_distance,\n",
    "        lambda_racial=lambda_racial,\n",
    "        lambda_capacity=lambda_capacity,\n",
    "        capacity_per_school=capacity_per_school,\n",
    "        capacity_slack=capacity_slack\n",
    "    )\n",
    "\n",
    "    # Prepare results DataFrame\n",
    "    assignments = []\n",
    "    for school, blocks in allocation.items():\n",
    "        for block in blocks:\n",
    "            assignments.append({'UniqueTract': block, 'UniqueSchoolID': school})\n",
    "\n",
    "    df_assignments = pd.DataFrame(assignments)\n",
    "\n",
    "    # Merge assignments with block data\n",
    "    df_results = pd.merge(df_assignments, gdf_blocks, on='UniqueTract', how='left')\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics(\n",
    "        df_results=df_results,\n",
    "        df_blocks=gdf_blocks,\n",
    "        dist=dist,\n",
    "        P_k=P_k,\n",
    "        school_names=school_names,\n",
    "        max_distance=max_distance\n",
    "    )\n",
    "    print(\"\\nEnvy-Free Algorithm Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    return df_results, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26393ed3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Run MILP Optimization\n",
    "def run_milp():\n",
    "    print(\"\\nRunning MILP Optimization...\")\n",
    "    result = solve_optimization(\n",
    "        df_blocks=gdf_blocks,\n",
    "        df_schools=gdf_schools,\n",
    "        dist=dist,\n",
    "        P_k=P_k,\n",
    "        BigM=BigM,\n",
    "        capacity_slack=capacity_slack,\n",
    "        lambda_cost=lambda_cost,\n",
    "        lambda_imbalance=lambda_imbalance,\n",
    "        lambda_compactness=lambda_compactness,\n",
    "        solver_time_limit=solver_time_limit\n",
    "    )\n",
    "    if result is None:\n",
    "        print(\"No solution found.\")\n",
    "        return None, None\n",
    "    df_results = result['assignments']\n",
    "    metrics = {\n",
    "        'family_cost': result['family_cost'],\n",
    "        'racial_imbalance': result['racial_imbalance'],\n",
    "        'compactness_penalty': result['compactness_penalty']\n",
    "    }\n",
    "    print(\"\\nMILP Optimization Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    return df_results, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f693989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Envy-Free Algorithm with Composite Valuations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Allocating Blocks:  15%|█▍        | 364/2460 [03:04<16:31,  2.11it/s]"
     ]
    }
   ],
   "source": [
    "# Run both optimizations\n",
    "df_eefx_results, eefx_metrics = run_envy_free()\n",
    "df_milp_results, milp_metrics = run_milp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986553a9",
   "metadata": {},
   "source": [
    "## 4. Grid Search over Lambda Values <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8f7e4a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Parameters for grid search\n",
    "lambda_values = [0.1, 0.5, 1, 2, 5]\n",
    "district_codes = gdf_blocks['district_code'].unique().tolist()\n",
    "capacity_slack = 1.05\n",
    "solver_time_limit = 60000  # 60 seconds\n",
    "parallel_processes = max(cpu_count() - 1, 1)  # Number of processes for parallel execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ac9a0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_experiments_for_district(district_code):\n",
    "    district_results = []\n",
    "\n",
    "    # Filter data for the district\n",
    "    district_blocks = gdf_blocks[gdf_blocks['district_code'] == district_code]\n",
    "    district_schools = gdf_schools[gdf_schools['district_code'] == district_code]\n",
    "    block_names = district_blocks['UniqueTract'].unique().tolist()\n",
    "    school_names = district_schools['UniqueSchoolID'].unique().tolist()\n",
    "\n",
    "    # Filter dist for the district\n",
    "    district_dist = {block: dist[block] for block in block_names}\n",
    "\n",
    "    # Compute P_k for the district\n",
    "    total_race_population = district_blocks[['White', 'Black', 'Asian']].sum().sum()\n",
    "    if total_race_population == 0:\n",
    "        total_race_population = 1e-6\n",
    "    P_k = {\n",
    "        'White': district_blocks['White'].sum() / total_race_population,\n",
    "        'Black': district_blocks['Black'].sum() / total_race_population,\n",
    "        'Asian': district_blocks['Asian'].sum() / total_race_population\n",
    "    }\n",
    "    max_possible_imbalance = sum([abs(1 - P_k[race]) for race in P_k])\n",
    "    max_distance = max([max(dist_row.values()) for dist_row in district_dist.values() if dist_row])\n",
    "    BigM = max_distance + 1\n",
    "\n",
    "    total_population = district_blocks['Population'].sum()\n",
    "    num_schools = len(school_names)\n",
    "    capacity_per_school = capacity_slack * (total_population / num_schools)\n",
    "\n",
    "    for lambda_value in tqdm(lambda_values, desc=f'District {district_code}'):\n",
    "        # Envy-Free Algorithm\n",
    "        allocation = eefx_allocation_composite(\n",
    "            df_blocks=district_blocks,\n",
    "            block_names=block_names,\n",
    "            school_names=school_names,\n",
    "            dist=district_dist,\n",
    "            P_k=P_k,\n",
    "            max_distance=max_distance,\n",
    "            max_possible_imbalance=max_possible_imbalance,\n",
    "            lambda_distance=lambda_value,\n",
    "            lambda_racial=lambda_value,\n",
    "            lambda_capacity=lambda_value,\n",
    "            capacity_per_school=capacity_per_school,\n",
    "            capacity_slack=capacity_slack\n",
    "        )\n",
    "        # Prepare results DataFrame\n",
    "        assignments = []\n",
    "        for school, blocks in allocation.items():\n",
    "            for block in blocks:\n",
    "                assignments.append({'UniqueTract': block, 'UniqueSchoolID': school})\n",
    "        df_assignments = pd.DataFrame(assignments)\n",
    "        df_results = pd.merge(df_assignments, district_blocks, on='UniqueTract', how='left')\n",
    "        # Compute metrics\n",
    "        metrics = compute_metrics(\n",
    "            df_results=df_results,\n",
    "            df_blocks=district_blocks,\n",
    "            dist=district_dist,\n",
    "            P_k=P_k,\n",
    "            school_names=school_names,\n",
    "            max_distance=max_distance\n",
    "        )\n",
    "        metrics.update({\n",
    "            'district_code': district_code,\n",
    "            'lambda_value': lambda_value,\n",
    "            'algorithm': 'Envy-Free'\n",
    "        })\n",
    "        district_results.append(metrics)\n",
    "\n",
    "        # MILP Optimization\n",
    "        result = solve_optimization(\n",
    "            df_blocks=district_blocks,\n",
    "            df_schools=district_schools,\n",
    "            dist=district_dist,\n",
    "            P_k=P_k,\n",
    "            BigM=BigM,\n",
    "            capacity_slack=capacity_slack,\n",
    "            lambda_cost=lambda_value,\n",
    "            lambda_imbalance=lambda_value,\n",
    "            lambda_compactness=lambda_value,\n",
    "            solver_time_limit=solver_time_limit\n",
    "        )\n",
    "        if result is not None:\n",
    "            metrics = {\n",
    "                'family_cost': result['family_cost'],\n",
    "                'racial_imbalance': result['racial_imbalance'],\n",
    "                'compactness_penalty': result['compactness_penalty'],\n",
    "                'district_code': district_code,\n",
    "                'lambda_value': lambda_value,\n",
    "                'algorithm': 'MILP'\n",
    "            }\n",
    "            district_results.append(metrics)\n",
    "        else:\n",
    "            print(f\"MILP did not find a solution for district {district_code} with lambda {lambda_value}\")\n",
    "\n",
    "    return district_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid search in parallel\n",
    "print(\"\\nRunning Grid Search over Districts and Lambda Values...\")\n",
    "with Pool(processes=parallel_processes) as pool:\n",
    "    all_results = []\n",
    "    for district_results in tqdm(pool.imap_unordered(run_experiments_for_district, district_codes), total=len(district_codes)):\n",
    "        all_results.extend(district_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45680488",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "# Save results to CSV\n",
    "df_results.to_csv('grid_search_results.csv', index=False)\n",
    "print(\"\\nGrid search results saved to 'grid_search_results.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2503c6",
   "metadata": {},
   "source": [
    "## 5. Visualizations and Analysis <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1afe1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to plot metrics over lambda values\n",
    "def plot_metric_over_lambda(df_results, metric, algorithm_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(\n",
    "        data=df_results[df_results['algorithm'] == algorithm_name],\n",
    "        x='lambda_value',\n",
    "        y=metric,\n",
    "        hue='district_code',\n",
    "        marker='o'\n",
    "    )\n",
    "    plt.title(f\"{metric.replace('_', ' ').title()} vs Lambda Value ({algorithm_name})\")\n",
    "    plt.xlabel('Lambda Value')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.legend(title='District Code', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics for Envy-Free algorithm\n",
    "print(\"\\nPlotting metrics for Envy-Free algorithm...\")\n",
    "for metric in ['family_cost', 'racial_imbalance', 'compactness_penalty', 'average_entropy', 'envy_count']:\n",
    "    plot_metric_over_lambda(df_results, metric, 'Envy-Free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c0f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics for MILP algorithm\n",
    "print(\"\\nPlotting metrics for MILP algorithm...\")\n",
    "for metric in ['family_cost', 'racial_imbalance', 'compactness_penalty']:\n",
    "    plot_metric_over_lambda(df_results, metric, 'MILP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfc9c7",
   "metadata": {},
   "source": [
    "## 6. Conclusion <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial optimization results if needed\n",
    "df_eefx_results.to_csv('eefx_initial_results.csv', index=False)\n",
    "df_milp_results.to_csv('milp_initial_results.csv', index=False)\n",
    "print(\"\\nInitial optimization results saved to 'eefx_initial_results.csv' and 'milp_initial_results.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e42751",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "- We successfully ran both Envy-Free and MILP optimizations using the preprocessed data.\n",
    "- We performed a grid search over different lambda values and districts.\n",
    "- Progress bars were added to track long-running computations.\n",
    "- The code handles distances and IDs consistently and efficiently.\n",
    "- The results include assignments and computed metrics, which were visualized for analysis."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
